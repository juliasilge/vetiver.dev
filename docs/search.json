[
  {
    "objectID": "learn-more/model-card.html",
    "href": "learn-more/model-card.html",
    "title": "Model cards for transparent, responsible reporting",
    "section": "",
    "text": "Good documentation helps us make sense of software, know when and how to use it, and understand its purpose. The same can be true of documentation or reporting for a deployed model, but it can be hard to know where to start. The paper ‚ÄúModel Cards for Model Reporting‚Äù (Mitchell et al.¬†2019) provides a suggested framework for organizing and presenting the essential facts about a deployed machine learning model. The vetiver package provides an R Markdown template for creating a ‚ÄúModel Card‚Äù for a published vetiver model. The template automates extracting some information from the model object, and provides structure for the model developer where automation is not possible.\nModel developers see a nudge to create a model card when they publish a model; we recommend that you create a model card when you deploy a model for the first time and refresh that model card as needed when new versions are deployed.\n\nlibrary(vetiver)\nlibrary(pins)\nmodel_board <- board_temp()\n\ncars_lm <- lm(mpg ~ ., data = mtcars)\nv <- vetiver_model(cars_lm, \"cars_linear\")\nvetiver_pin_write(model_board, v)\n\nCreating new version '20220719T223429Z-9ca24'\nWriting to pin 'cars_linear'\n\nCreate a Model Card for your published model\n‚Ä¢ Model Cards provide a framework for transparent, responsible reporting\n‚Ä¢ Use the vetiver `.Rmd` template as a place to start\n\n\n(Learn more about silencing messages like this if desired.)"
  },
  {
    "objectID": "learn-more/model-card.html#accessing-the-template",
    "href": "learn-more/model-card.html#accessing-the-template",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Accessing the template",
    "text": "Accessing the template\n\n\n\n\n\n\nWarning\n\n\n\nAs of this writing, the model card template is only available for R Markdown.\n\n\nTo use the vetiver model card template from RStudio, access through File -> New File -> R Markdown. This will open the dialog box where you can select from one of the available templates:\n\n\n\n\n\nIf you are not using RStudio, you‚Äôll also need to install Pandoc. Then, use the rmarkdown::draft() function to create the model card:\nrmarkdown::draft(\n    \"my_model_card.Rmd\", \n    template = \"vetiver_model_card\", \n    package = \"vetiver\"\n)"
  },
  {
    "objectID": "learn-more/model-card.html#model-card-outline",
    "href": "learn-more/model-card.html#model-card-outline",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Model card outline",
    "text": "Model card outline\nThere are several sections in the model card framework used here.\n\nModel details: Some details about your model can be determined from the model object itself, but some (like who developed the model and license or citation information) need to be provided by you.\nIntended use: Outline the intended use and users of the model, and perhaps also what types of use would be out of scope.\nImportant aspects/factors: What are the demographic, environmental, technical, or other aspects that are relevant to the context of the model?\nPerformance metrics: Communicate which metrics are being used to evaluate the model, and why these are a good fit for the model‚Äôs context and domain.\nTraining data & evaluation data: Some specific dataset was used to train the model, so be sure to share basic details about its characteristics. (Some information about the training data can be extracted from the model object itself.) Some (probably different) specific dataset is used to evaluate the model in the context of the model card, so also explain what the evaluation data is like.\nQuantitative analyses: Provide the results of evaluating the model using your chosen metrics and the evaluation data. Be sure to present both overall results (for the dataset as a whole) and disaggregated results, especially with any aspects (demographic, environmental, or other) in mind that have been identified as important for this model. You can use both tables and visualization to present these quantitative analyses.\nEthical considerations: Share ethical considerations and any possible solutions considered. Some specific aspects to note are any sensitive data used, impact on human life, possible risks and harms, and important use cases.\nCaveats & recommendations: As the model developer, you likely have the most domain knowledge of what the model can and cannot do. This section is a good place to share any additional thoughts, perhaps including how your own identity may or may not come into play in the model‚Äôs context."
  },
  {
    "objectID": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "href": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Can‚Äôt I just delete the section on ethical considerations?",
    "text": "Can‚Äôt I just delete the section on ethical considerations?\nIt‚Äôs possible that a given machine learning model may not have obvious caveats, ethical challenges, or demographic aspects, or that they are largely unknown. However, we strongly advise that instead of deleting any such section because you have incomplete or imprecise information, you note your own process and considerations. Also, consider the possibility of gathering feedback from those impacted by the machine learning system, especially those with marginalized identities.\nThe process of documenting the extent and limits of a machine learning system is part of transparent, responsible reporting. A model card framework such as this is a helpful tool and some parts of a model card can be automated, but ultimately the extent of its value depends on you. From Mitchell et al.¬†(2019):\n\nTherefore the usefulness and accuracy of a model card relies on the integrity of the creator(s) of the card itself."
  },
  {
    "objectID": "learn-more/parity-checklist.html",
    "href": "learn-more/parity-checklist.html",
    "title": "Function parity for R and Python",
    "section": "",
    "text": "Function\nR\nPython\n\n\n\n\nCreate a vetiver object for deployment of a trained model\nvetiver_model() new_vetiver_model()\nVetiverModel()\n\n\nRead and write a trained model to a board of models\nvetiver_pin_write() vetiver_pin_read()\nvetiver_pin_write() VetiverModel.from_pin()\n\n\nCreate an API to predict with a deployable vetiver_model() object\nvetiver_api() vetiver_pr_post() vetiver_pr_docs()\nVetiverAPI() VetiverAPI.vetiver_post()\n\n\nWrite a deployable API file for a vetiver model\nvetiver_write_plumber()\nwrite_app()\n\n\nDeploy a vetiver model API to RStudio Connect\nvetiver_deploy_rsconnect()\ndeploy_rsconnect()\n\n\nCreate a model API endpoint object for prediction\nvetiver_endpoint()\nvetiver_endpoint()\n\n\nPost new data to a deployed model API endpoint and return predictions\npredict()\npredict()\n\n\nFully attach or load packages for making model predictions\nattach_pkgs() load_pkgs()\nload_pkgs()\n\n\nModel handler functions for API endpoint\nhandler_startup() handler_predict()\nVetiverHandler.handler_predict()\n\n\nIdentify data types for each column in an input data prototype\nmap_request_body()\n\n\n\nModel constructor methods\nvetiver_create_description() vetiver_prepare_model()\nVetiverHandler.describe()\n\n\nMetadata constructors for vetiver model object\nvetiver_meta() vetiver_create_meta()\nVetiverHandler.create_meta() vetiver_create_meta()\n\n\nCreate a vetiver input data prototype\nvetiver_ptype() vetiver_create_ptype()\nvetiver_create_ptype()\n\n\nConvert new data at prediction time using input data prototype\nvetiver_type_convert()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MLOps with vetiver",
    "section": "",
    "text": "Vetiver, the oil of tranquility, is used as a stabilizing ingredient in perfumery to preserve more volatile fragrances.\n\nThe goal of vetiver is to provide fluent tooling to version, deploy, and monitor a trained model. Functions handle both recording and checking the model‚Äôs input data prototype, and predicting from a remote API endpoint.\n\n\n\n\n\n\n\n\n\n\n\nData scientists have effective tools that they ‚ù§Ô∏è to:\n\n\n\n\ncollect data\nprepare, manipulate, refine data\ntrain models\n\n\n\n\n\n\n\n\n\nThere is a lack üò© of effective tools to:\n\n\n\n\nversion and publish models\nput models into production\nmonitor model performance\n\n\n\nUse vetiver to version and deploy your trained models.\n\nRPython\n\n\n\nlibrary(vetiver)\ncars_lm <- lm(mpg ~ ., data = mtcars)\nvetiver_model(cars_lm, \"cars_linear\")\n\n\n‚îÄ‚îÄ cars_linear ‚îÄ <butchered_lm> model for deployment \nAn OLS linear regression model using 10 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nfrom vetiver.data import mtcars\nfrom sklearn import linear_model\n\nmodel = linear_model.LinearRegression().fit(mtcars, mtcars[\"mpg\"])\nv = VetiverModel(model, model_name = \"cars_linear\", \n                 save_ptype = True, ptype_data = mtcars)\nv.description\n\n\"Scikit-learn <class 'sklearn.linear_model._base.LinearRegression'> model\""
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About vetiver",
    "section": "",
    "text": "Development of vetiver is sponsored by RStudio, PBC."
  },
  {
    "objectID": "about.html#is-vetiver-open-source",
    "href": "about.html#is-vetiver-open-source",
    "title": "About vetiver",
    "section": "Is vetiver open source?",
    "text": "Is vetiver open source?\nThe vetiver Python and R packages are released under the MIT license."
  },
  {
    "objectID": "about.html#what-are-different-ways-you-can-contribute",
    "href": "about.html#what-are-different-ways-you-can-contribute",
    "title": "About vetiver",
    "section": "What are different ways you can contribute?",
    "text": "What are different ways you can contribute?\n\nAnswer questions\nYou can help others use and learn vetiver by answering questions on the RStudio community site, Stack Overflow, and Twitter. Many people asking for help with vetiver don‚Äôt know what a reproducible example or ‚Äúreprex‚Äù is, or how to craft one. Acknowledging an individual‚Äôs problem, showing them how to build a reprex, and pointing them to helpful resources are all enormously beneficial, even if you don‚Äôt immediately solve their problem.\nRemember that while you might have seen a problem a hundred times before, it‚Äôs new to the person asking it. Be patient, polite, and empathetic.\n\n\nFile issues\nIf you‚Äôve found a bug, first create a minimal reproducible example. Spend some time working to make it as minimal as possible; the more time you spend doing this, the easier it is to fix the bug. When your reprex is ready, file it on the GitHub repo of the appropriate package, either Python or R.\nThe vetiver team often focuses on one package at a time to reduce context switching and be more efficient. We may not address each issue right away, but we will use the reproducible example you create to understand your problem when it is time to focus on that package.\n\n\nContribute documentation\nDocumentation is a high priority for vetiver, and pull requests to correct or improve documentation are welcome.\n\n\nContribute code\nIf you are a more experienced R or Python programmer, you may have the inclination, interest, and ability to contribute directly to package development. Before you submit a pull request to vetiver, always file an issue and confirm the vetiver team agrees with your idea and is happy with your basic proposal.\nWe use the tidyverse style guide for R and the PEP 8 style guide for Python. Using a style guide keeps your new code and documentation matching the existing style, and makes the review process much smoother."
  },
  {
    "objectID": "get-started/deploy.html",
    "href": "get-started/deploy.html",
    "title": "Deploy",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidymodels)\nlibrary(vetiver)\nlibrary(pins)\n\ncar_mod <-\n    workflow(mpg ~ ., decision_tree(mode = \"regression\")) %>%\n    fit(mtcars)\nv <- vetiver_model(car_mod, \"cars_mpg\")\nmodel_board <- board_folder(\"pins-r\", versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver.data import mtcars\nfrom vetiver import VetiverModel, vetiver_pin_write\nfrom sklearn import tree\nfrom pins import board_folder\n\ncar_mod = tree.DecisionTreeRegressor().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars.drop(columns=\"mpg\"))\n\nmodel_board = board_folder(\"pins-py\", allow_pickle_read=True)\nvetiver_pin_write(model_board, v)"
  },
  {
    "objectID": "get-started/deploy.html#create-a-rest-api-for-deployment",
    "href": "get-started/deploy.html#create-a-rest-api-for-deployment",
    "title": "Deploy",
    "section": "Create a REST API for deployment",
    "text": "Create a REST API for deployment\nYou can deploy your model by creating a special Plumber router in R or a FastAPI router in Python, and adding a POST endpoint for making predictions.\n\nRPython\n\n\n\nlibrary(plumber)\npr() %>%\n  vetiver_api(v)\n\n# Plumber router with 2 endpoints, 4 filters, and 1 sub-router.\n# Use `pr_run()` on this object to start the API.\n‚îú‚îÄ‚îÄ[queryString]\n‚îú‚îÄ‚îÄ[body]\n‚îú‚îÄ‚îÄ[cookieParser]\n‚îú‚îÄ‚îÄ[sharedSecret]\n‚îú‚îÄ‚îÄ/logo\n‚îÇ  ‚îÇ # Plumber static router serving from directory: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library/vetiver\n‚îú‚îÄ‚îÄ/ping (GET)\n‚îî‚îÄ‚îÄ/predict (POST)\n\n\nTo start a server using this object, pipe (%>%) to pr_run(port = 8080) or your port of choice.\n\n\n\nfrom vetiver import VetiverAPI\napp = VetiverAPI(v, check_ptype = True)\n\nTo start a server using this object, use app.run(port = 8080) or your port of choice.\n\n\n\nYou can interact with your vetiver API via automatically generated, detailed visual documentation.\n\n\n\n\n\n\n\n\n\n\n\n\nFastAPI and Plumber APIs such as these can be hosted in a variety of ways. You can create a ready-to-go file for deployment that is especially suited for RStudio Connect.\n\nRPython\n\n\n\nvetiver_write_plumber(model_board, \"cars_mpg\")\n\n\n\n# Generated by the vetiver package; edit with care\n\nlibrary(pins)\nlibrary(plumber)\nlibrary(rapidoc)\nlibrary(vetiver)\nb <- board_folder(path = \"pins-r\")\nv <- vetiver_pin_read(b, \"cars_mpg\", version = \"20220719T223436Z-04d88\")\n\n#* @plumber\nfunction(pr) {\n    pr %>% vetiver_api(v)\n}\n\n\nFor RStudio Connect, you can streamline this deployment process even more by using vetiver_deploy_rsconnect(model_board, \"cars_mpg\").\n\n\n\napp_file = vetiver.write_app(model_board, \"cars_mpg\")\n\n\n\nfrom vetiver import VetiverModel\nimport vetiver\nimport pins\n\n\nb = pins.board_folder('pins-py')\nv = VetiverModel.from_pin(b, 'cars_mpg', version = '20220719T161222Z-0cb02')\n\nvetiver_api = vetiver.VetiverAPI(v)\napi = vetiver_api.app\n\n\n\n\n\nIn a real-world situation, you would see something like board_rsconnect() or board_s3() here instead of our temporary demo board.\n\n\n\n\n\n\nImportant\n\n\n\nNotice that the deployment is strongly linked to a specific version of the pinned model; if you pin another version of the model after you deploy your model, your deployed model will not be affected."
  },
  {
    "objectID": "get-started/deploy.html#generate-a-dockerfile",
    "href": "get-started/deploy.html#generate-a-dockerfile",
    "title": "Deploy",
    "section": "Generate a Dockerfile",
    "text": "Generate a Dockerfile\nFor deploying a vetiver API to infrastructure other than RStudio Connect, such as Google Cloud Run, AWS, or Azure, you likely will want to build a Docker container.\n\n\n\n\n\n\nNote\n\n\n\nYou can use any pins board with Docker, like board_folder() or board_rsconnect(), as long as your Docker container can authenticate to your pins board.\n\n\n\nRPython\n\n\n\nvetiver_write_docker(v)\n\n\n\n# Generated by the vetiver package; edit with care\n\nFROM rocker/r-ver:4.2.0\nENV RENV_CONFIG_REPOS_OVERRIDE https://packagemanager.rstudio.com/cran/latest\n\nRUN apt-get update -qq && apt-get install -y --no-install-recommends \\\n  libcurl4-openssl-dev \\\n  libicu-dev \\\n  libsodium-dev \\\n  libssl-dev \\\n  make\n\nCOPY vetiver_renv.lock renv.lock\nRUN Rscript -e \"install.packages('renv')\"\nRUN Rscript -e \"renv::restore()\"\nCOPY plumber.R /opt/ml/plumber.R\nEXPOSE 8000\nENTRYPOINT [\"R\", \"-e\", \"pr <- plumber::plumb('/opt/ml/plumber.R'); pr$run(host = '0.0.0.0', port = 8000)\"]\n\n\nWhen you run vetiver_write_docker(), you generate two files: the Dockerfile itself and the renv.lock file to capture your model dependencies.\n\n\n\nvetiver.write_docker(app_file)\n\n\n\n# # Generated by the vetiver package; edit with care\n# start with python base image\nFROM python:3.8\n\n# create directory in container for vetiver files\nWORKDIR /vetiver\n\n# copy  and install requirements\nCOPY vetiver_requirements.txt /vetiver/requirements.txt\n\n#\nRUN pip install --no-cache-dir --upgrade -r /vetiver/requirements.txt\n\n# copy app file\nCOPY ./app.py /vetiver/app\n\n# expose port\nEXPOSE 8080\n\n# run vetiver API\nCMD [\"uvicorn\", \"app.app:api\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n\n\nTo build the Docker image, you need two files: the Dockerfile itself generated via vetiver_write_docker() and a requirements.txt file to capture your model dependencies. If you don‚Äôt already have a requirements file for your project, vetiver.load_pkgs() will generate one for you, with the name vetiver_requirements.txt.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you build such a Docker container with docker build, all the packages needed to make a prediction with your model are installed into the container.\nWhen you run the Docker container, you can pass in environment variables (for authentication to your pins board, for example) with docker run --env-file .Renviron."
  },
  {
    "objectID": "get-started/deploy.html#predict-from-your-model-endpoint",
    "href": "get-started/deploy.html#predict-from-your-model-endpoint",
    "title": "Deploy",
    "section": "Predict from your model endpoint",
    "text": "Predict from your model endpoint\nA model deployed via vetiver can be treated as a special vetiver_endpoint() object.\n\nRPython\n\n\n\nendpoint <- vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\nendpoint\n\n\n‚îÄ‚îÄ A model API endpoint for prediction: \nhttp://127.0.0.1:8080/predict\n\n\n\n\n\nfrom vetiver.server import predict, vetiver_endpoint\nendpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict/\")\nendpoint\n\n'http://127.0.0.1:8080/predict/'\n\n\n\n\n\nIf such a deployed model endpoint is running via one process (either remotely on a server or locally, perhaps via a background job in the RStudio IDE), you can make predictions with that deployed model and new data in another, separate process1.\n\nRPython\n\n\n\nnew_car <- tibble(cyl = 4,  disp = 200, \n                  hp = 100, drat = 3,\n                  wt = 3,   qsec = 17, \n                  vs = 0,   am = 1,\n                  gear = 4, carb = 2)\npredict(endpoint, new_car)\n\n# A tibble: 11 √ó 1\n   .pred\n   <chr>      \n 1 22.3       \n\n\n\nimport pandas as pd\nnew_car_dict = {\"cyl\": [4], \"disp\": [200], \n                 \"hp\": [100], \"drat\": [3],\n                 \"wt\": [3], \"qsec\": [17], \n                 \"vs\": [0], \"am\": [1],\n                 \"gear\": [4], \"carb\": [2]}\nnew_car = pd.DataFrame(new_car_dict)\npredict(endpoint, new_car)\n\n  prediction\n0       21.0\n\n\n\nBeing able to predict with a vetiver model endpoint takes advantage of the model‚Äôs input data prototype and other metadata that is stored with the model."
  },
  {
    "objectID": "get-started/index.html",
    "href": "get-started/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "The vetiver framework for MLOps tasks is built for data science teams using R and/or Python, with a native, fluent experience for both. It is built to be extensible, with methods that can support many kinds of models."
  },
  {
    "objectID": "get-started/index.html#installation",
    "href": "get-started/index.html#installation",
    "title": "Getting Started",
    "section": "Installation",
    "text": "Installation\n\nRPython\n\n\nYou can use vetiver with:\n\na tidymodels workflow\ncaret\nmlr3\nXGBoost\nranger\nlm() and glm()\n\nYou can install the released version of vetiver from CRAN:\n\ninstall.packages(\"vetiver\")\n\nAnd the development version from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidymodels/vetiver-r\")\n\n\n\nYou can use vetiver with:\n\nscikit-learn\nPyTorch\n\nYou can install the released version of vetiver from PyPI:\n\npython -m pip install vetiver\n\nAnd the development version from GitHub with:\n\npython -m pip install git+https://github.com/rstudio/vetiver-python"
  },
  {
    "objectID": "get-started/index.html#train-a-model",
    "href": "get-started/index.html#train-a-model",
    "title": "Getting Started",
    "section": "Train a model",
    "text": "Train a model\nFor this example, let‚Äôs work with data on fuel efficiency for cars to predict miles per gallon.\n\nRPython\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a tidymodels workflow that encompasses both feature engineering and model estimation.\n\nlibrary(tidymodels)\n\ncar_mod <-\n    workflow(mpg ~ ., linear_reg()) %>%\n    fit(mtcars)\n\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a scikit-learn linear model.\n\nfrom vetiver.data import mtcars\nfrom sklearn import linear_model\n\ncar_mod = linear_model.LinearRegression().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\n\n\n\nThis car_mod object is a fitted model, with model parameters estimated using mtcars."
  },
  {
    "objectID": "get-started/index.html#create-a-vetiver-model",
    "href": "get-started/index.html#create-a-vetiver-model",
    "title": "Getting Started",
    "section": "Create a vetiver model",
    "text": "Create a vetiver model\nWe can create a vetiver_model() in R or VetiverModel() in Python from the trained model; a vetiver model object collects the information needed to store, version, and deploy a trained model.\n\nRPython\n\n\n\nlibrary(vetiver)\nv <- vetiver_model(car_mod, \"cars_mpg\")\nv\n\n\n‚îÄ‚îÄ cars_mpg ‚îÄ <butchered_workflow> model for deployment \nA lm regression modeling workflow using 10 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)\nv.description\n\n\"Scikit-learn <class 'sklearn.linear_model._base.LinearRegression'> model\"\n\n\n\n\n\nThink of this vetiver model as a deployable model object."
  },
  {
    "objectID": "get-started/version.html",
    "href": "get-started/version.html",
    "title": "Version",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidymodels)\nlibrary(vetiver)\n\ncar_mod <-\n    workflow(mpg ~ ., linear_reg()) %>%\n    fit(mtcars)\nv <- vetiver_model(car_mod, \"cars_mpg\")\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver.data import mtcars\nfrom vetiver import VetiverModel\nfrom sklearn import linear_model\n\ncar_mod = linear_model.LinearRegression().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)"
  },
  {
    "objectID": "get-started/version.html#store-and-version-your-model",
    "href": "get-started/version.html#store-and-version-your-model",
    "title": "Version",
    "section": "Store and version your model",
    "text": "Store and version your model\nYou can store and version your model by choosing a pins ‚Äúboard‚Äù for it. Your board for model pins can be set up to use a local folder, RStudio Connect, Amazon S3, and more. When we write the vetiver model to our board, the binary model object is stored on our board together with necessary metadata, like the packages needed to make a prediction and the model‚Äôs input data prototype for checking new data at prediction time.\n\n\n\n\n\n\nNote\n\n\n\nWe‚Äôll use a temporary board that will be automatically deleted for this demo, but for your real work, you will want to choose the best board for your particular infrastructure.\n\n\n\nRPython\n\n\nMost pins boards have versioning turned on by default, but we can turn it on explicitly for our temporary demo board.\n\nlibrary(pins)\nmodel_board <- board_temp(versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\nfrom pins import board_temp\nfrom vetiver import vetiver_pin_write\nmodel_board = board_temp(versioned = True, allow_pickle_read = True)\nvetiver_pin_write(model_board, v)\n\n\n\n\nLet‚Äôs train a new kind of model for mtcars, a decision tree instead of our original linear model.\n\n\n\n\nRPython\n\n\n\ncar_mod <-\n    workflow(mpg ~ ., decision_tree(mode = \"regression\")) %>%\n    fit(mtcars)\n\nv <- vetiver_model(car_mod, \"cars_mpg\")\n\nmodel_board %>% vetiver_pin_write(v)\n\nCreating new version '20220719T223457Z-9b649'\nWriting to pin 'cars_mpg'\n\n\n\n\n\nfrom sklearn import tree\ncar_mod = tree.DecisionTreeRegressor().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)\nvetiver_pin_write(model_board, v)\n\n\n\n\nBoth versions are stored, and we have access to both.\n\nRPython\n\n\n\nmodel_board %>% pin_versions(\"cars_mpg\")\n\n# A tibble: 2 √ó 3\n  version                created             hash \n  <chr>                  <dttm>              <chr>\n1 20220719T223455Z-4a65a 2022-07-19 16:34:00 4a65a\n2 20220719T223457Z-9b649 2022-07-19 16:34:00 9b649\n\n\n\n\n\nmodel_board.pin_versions(\"cars_mpg\")\n\n              created   hash                 version\n0 2022-07-19 16:34:55  dd3e7  20220719T163455Z-dd3e7\n1 2022-07-19 16:34:57  afa6c  20220719T163457Z-afa6c\n\n\n\n\n\nThe primary purpose of pins is to make it easy to share data artifacts, so depending on the board you choose, your pinned vetiver model can be shareable with your collaborators."
  },
  {
    "objectID": "get-started/monitor.html",
    "href": "get-started/monitor.html",
    "title": "Monitor",
    "section": "",
    "text": "Once a model is deployed, it is important to monitor its statistical performance. Machine learning can break quietly; a model can continue returning predictions without error, even if it is performing poorly. Without monitoring for degradation, this silent failure can continue undiagnosed. The vetiver framework offers functions to fluently compute, store, and plot model metrics. These functions are particularly suited to monitoring your model using multiple performance metrics over time.\nWhen a model is deployed, new data comes in over time, even if time is not a feature for prediction. Even if your model does not explicitly use any dates, a measure of time like a date can affect your model performance."
  },
  {
    "objectID": "get-started/monitor.html#build-a-model",
    "href": "get-started/monitor.html#build-a-model",
    "title": "Monitor",
    "section": "Build a model",
    "text": "Build a model\n\nRPython\n\n\n\n\nShow the code from previous steps\nlibrary(pins)\nlibrary(vetiver)\nlibrary(workflows)\n\nmodel_board <- board_folder(path = \"pins-r\")\nv <- vetiver_pin_read(model_board, \"cars_mpg\")\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver import VetiverModel\nfrom pins import board_folder\n\nmodel_board = board_folder(\"pins-py\", allow_pickle_read=True)\nv = VetiverModel.from_pin(model_board, \"cars_mpg\")"
  },
  {
    "objectID": "get-started/monitor.html#compute-metrics",
    "href": "get-started/monitor.html#compute-metrics",
    "title": "Monitor",
    "section": "Compute metrics",
    "text": "Compute metrics\nLet‚Äôs say we collect new data on fuel efficiency in cars and we want to monitor the performance of our model over time. We can compute multiple metrics at once over a certain time aggregation.\n\nRPython\n\n\n\nlibrary(vetiver)\nlibrary(tidyverse)\ncars <- read_csv(\"https://vetiver.rstudio.com/get-started/new-cars.csv\")\noriginal_cars <- slice(cars, 1:14)\n\noriginal_metrics <-\n    augment(v, new_data = original_cars) %>%\n    vetiver_compute_metrics(date_obs, \"week\", mpg, .pred)\n\nWarning: A correlation computation is required, but `estimate` is constant\nand has 0 standard deviation, resulting in a divide by 0 error. `NA` will be\nreturned.\n\n\nWarning: A correlation computation is required, but `estimate` is constant\nand has 0 standard deviation, resulting in a divide by 0 error. `NA` will be\nreturned.\n\noriginal_metrics\n\n# A tibble: 9 √ó 5\n  .index        .n .metric .estimator .estimate\n  <date>     <int> <chr>   <chr>          <dbl>\n1 2022-03-15     2 rmse    standard       2.49 \n2 2022-03-15     2 rsq     standard      NA    \n3 2022-03-15     2 mae     standard       2.33 \n4 2022-03-17     7 rmse    standard       2.51 \n5 2022-03-17     7 rsq     standard       0.907\n6 2022-03-17     7 mae     standard       1.96 \n7 2022-03-24     5 rmse    standard       4.05 \n8 2022-03-24     5 rsq     standard      NA    \n9 2022-03-24     5 mae     standard       3.42 \n\n\n\n\n\nimport vetiver\n\nimport pandas as pd\nfrom sklearn import metrics\nfrom datetime import timedelta\n\ncars = pd.read_csv(\"https://vetiver.rstudio.com/get-started/new-cars.csv\")\noriginal_cars = cars.iloc[:14, :]\noriginal_cars[\"preds\"] = v.model.predict(original_cars.drop(columns=[\"date_obs\", \"mpg\"]))\n\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nmetric_set = [metrics.mean_absolute_error, metrics.mean_squared_error, metrics.r2_score]\ntd = timedelta(weeks = 1)\n\noriginal_metrics = vetiver.compute_metrics(\n    data = original_cars, \n    date_var = \"date_obs\", \n    period = td, \n    metric_set = metric_set, \n    truth = \"mpg\", \n    estimate = \"preds\"\n)\n\noriginal_metrics\n\n       index  n               metric   estimate\n0 2022-03-15  7  mean_absolute_error   1.528922\n1 2022-03-15  7   mean_squared_error   4.271549\n2 2022-03-15  7             r2_score   0.793702\n3 2022-03-22  7  mean_absolute_error   3.991518\n4 2022-03-22  7   mean_squared_error  27.570905\n5 2022-03-22  7             r2_score  -0.785869"
  },
  {
    "objectID": "get-started/monitor.html#pin-metrics",
    "href": "get-started/monitor.html#pin-metrics",
    "title": "Monitor",
    "section": "Pin metrics",
    "text": "Pin metrics\nThe first time you pin monitoring metrics, you can write to a board as normal. However, when adding new metrics measurements to your pin as you continue to gather new data and monitor, you may have dates that overlap with those already in the pin, depending on your monitoring strategy. You can choose how to handle overlapping dates with the overwrite argument.\n\nRPython\n\n\n\nmodel_board %>% pin_write(original_metrics, \"tree_metrics\")\n\n# dates overlap with existing metrics:\nnew_cars <- slice(cars, -1:-7)\nnew_metrics <-\n    augment(v, new_data = new_cars) %>%\n    vetiver_compute_metrics(date_obs, \"week\", mpg, .pred)\n\nmodel_board %>%\n    vetiver_pin_metrics(new_metrics, \"tree_metrics\", overwrite = TRUE)\n\n\n\n\nimport vetiver\nimport pins\n\nmodel_board.pin_write(original_metrics, \"tree_metrics\", type = \"csv\")\n\n# dates overlap with existing metrics:\nnew_cars = cars.iloc[7:, :]\nnew_cars[\"preds\"] = v.model.predict(new_cars.drop(columns=[\"date_obs\", \"mpg\"]))\nnew_metrics = vetiver.compute_metrics(\n    data = new_cars, \n    date_var = \"date_obs\", \n    period = td, \n    metric_set = metric_set, \n    truth = \"mpg\", \n    estimate = \"preds\"\n)\n                    \nvetiver.pin_metrics(model_board, new_metrics, \"tree_metrics\", overwrite = True)"
  },
  {
    "objectID": "get-started/monitor.html#plot-metrics",
    "href": "get-started/monitor.html#plot-metrics",
    "title": "Monitor",
    "section": "Plot metrics",
    "text": "Plot metrics\nYou can visualize your set of computed metrics and your model‚Äôs performance1.\n\nRPython\n\n\n\nlibrary(ggplot2)\nmonitoring_metrics <- model_board %>% pin_read(\"tree_metrics\")\nvetiver_plot_metrics(monitoring_metrics) +\n    scale_size(range = c(2, 4))\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n\nmonitoring_metrics = model_board.pin_read(\"tree_metrics\")\np = vetiver.plot_metrics(df_metrics = monitoring_metrics)\np.show()"
  },
  {
    "objectID": "get-started/monitor.html#build-a-dashboard",
    "href": "get-started/monitor.html#build-a-dashboard",
    "title": "Monitor",
    "section": "Build a dashboard",
    "text": "Build a dashboard\nThe vetiver package provides an R Markdown template for creating a monitoring dashboard. The template automates extracting some information from your metrics, and provides a way to extend the dashboard for a custom monitoring implementation."
  }
]