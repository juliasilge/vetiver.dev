[
  {
    "objectID": "learn-more/model-card.html",
    "href": "learn-more/model-card.html",
    "title": "Model cards for transparent, responsible reporting",
    "section": "",
    "text": "Good documentation helps us make sense of software, know when and how to use it, and understand its purpose. The same can be true of documentation or reporting for a deployed model, but it can be hard to know where to start. The paper ‚ÄúModel Cards for Model Reporting‚Äù (Mitchell et al.¬†2019) provides a suggested framework for organizing and presenting the essential facts about a deployed machine learning model. The vetiver package provides an R Markdown template for creating a ‚ÄúModel Card‚Äù for a published vetiver model. The template automates extracting some information from the model object, and provides structure for the model developer where automation is not possible.\nModel developers see a nudge to create a model card when they publish a model; we recommend that you create a model card when you deploy a model for the first time and refresh that model card as needed when new versions are deployed.\n\nlibrary(vetiver)\nlibrary(pins)\nmodel_board <- board_temp()\n\ncars_lm <- lm(mpg ~ ., data = mtcars)\nv <- vetiver_model(cars_lm, \"cars_linear\")\nvetiver_pin_write(model_board, v)\n\nCreating new version '20220511T215348Z-9ca24'\nWriting to pin 'cars_linear'\n\nCreate a Model Card for your published model\n‚Ä¢ Model Cards provide a framework for transparent, responsible reporting\n‚Ä¢ Use the vetiver `.Rmd` template as a place to start\n\n\n(Learn more about silencing messages like this if desired.)"
  },
  {
    "objectID": "learn-more/model-card.html#accessing-the-template",
    "href": "learn-more/model-card.html#accessing-the-template",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Accessing the template",
    "text": "Accessing the template\n\n\n\n\n\n\nWarning\n\n\n\nAs of this writing, the model card template is only available for R Markdown.\n\n\nTo use the vetiver model card template from RStudio, access through File -> New File -> R Markdown. This will open the dialog box where you can select from one of the available templates:\n\nIf you are not using RStudio, you‚Äôll also need to install Pandoc. Then, use the rmarkdown::draft() function to create the model card:\nrmarkdown::draft(\n    \"my_model_card.Rmd\", \n    template = \"vetiver_model_card\", \n    package = \"vetiver\"\n)"
  },
  {
    "objectID": "learn-more/model-card.html#model-card-outline",
    "href": "learn-more/model-card.html#model-card-outline",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Model card outline",
    "text": "Model card outline\nThere are several sections in the model card framework used here.\n\nModel details: Some details about your model can be determined from the model object itself, but some (like who developed the model and license or citation information) need to be provided by you.\nIntended use: Outline the intended use and users of the model, and perhaps also what types of use would be out of scope.\nImportant aspects/factors: What are the demographic, environmental, technical, or other aspects that are relevant to the context of the model?\nPerformance metrics: Communicate which metrics are being used to evaluate the model, and why these are a good fit for the model‚Äôs context and domain.\nTraining data & evaluation data: Some specific dataset was used to train the model, so be sure to share basic details about its characteristics. (Some information about the training data can be extracted from the model object itself.) Some (probably different) specific dataset is used to evaluate the model in the context of the model card, so also explain what the evaluation data is like.\nQuantitative analyses: Provide the results of evaluating the model using your chosen metrics and the evaluation data. Be sure to present both overall results (for the dataset as a whole) and disaggregated results, especially with any aspects (demographic, environmental, or other) in mind that have been identified as important for this model. You can use both tables and visualization to present these quantitative analyses.\nEthical considerations: Share ethical considerations and any possible solutions considered. Some specific aspects to note are any sensitive data used, impact on human life, possible risks and harms, and important use cases.\nCaveats & recommendations: As the model developer, you likely have the most domain knowledge of what the model can and cannot do. This section is a good place to share any additional thoughts, perhaps including how your own identity may or may not come into play in the model‚Äôs context."
  },
  {
    "objectID": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "href": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Can‚Äôt I just delete the section on ethical considerations?",
    "text": "Can‚Äôt I just delete the section on ethical considerations?\nIt‚Äôs possible that a given machine learning model may not have obvious caveats, ethical challenges, or demographic aspects, or that they are largely unknown. However, we strongly advise that instead of deleting any such section because you have incomplete or imprecise information, you note your own process and considerations. Also, consider the possibility of gathering feedback from those impacted by the machine learning system, especially those with marginalized identities.\nThe process of documenting the extent and limits of a machine learning system is part of transparent, responsible reporting. A model card framework such as this is a helpful tool and some parts of a model card can be automated, but ultimately the extent of its value depends on you. From Mitchell et al.¬†(2019):\n\nTherefore the usefulness and accuracy of a model card relies on the integrity of the creator(s) of the card itself."
  },
  {
    "objectID": "learn-more/parity-checklist.html",
    "href": "learn-more/parity-checklist.html",
    "title": "Function parity for R and Python",
    "section": "",
    "text": "Function\nR\nPython\n\n\n\n\nCreate a vetiver object for deployment of a trained model\nvetiver_model() new_vetiver_model()\nVetiverModel()\n\n\nRead and write a trained model to a board of models\nvetiver_pin_write() vetiver_pin_read()\nvetiver_pin_write() vetiver_pin_read()\n\n\nCreate an API to predict with a deployable vetiver_model() object\nvetiver_api() vetiver_pr_post() vetiver_pr_docs()\nVetiverAPI() VetiverAPI.vetiver_post()\n\n\nWrite a deployable API file for a vetiver model\nvetiver_write_plumber()\nvetiver_write_app()\n\n\nDeploy a vetiver model API to RStudio Connect\nvetiver_deploy_rsconnect()\n\n\n\nCreate a model API endpoint object for prediction\nvetiver_endpoint()\nvetiver_endpoint()\n\n\nPost new data to a deployed model API endpoint and return predictions\npredict(<vetiver_endpoint>)\nVetiverAPI.predict()\n\n\nFully attach or load packages for making model predictions\nattach_pkgs() load_pkgs()\nload_pkgs()\n\n\nModel handler functions for API endpoint\nhandler_startup() handler_predict()\nVetiverModel.translator.handler_startup() VetiverModel.translator.handler_predict()\n\n\nIdentify data types for each column in an input data prototype\nmap_request_body()\n\n\n\nModel constructor methods\nvetiver_create_description() vetiver_prepare_model()\nVetiverModel.translator.create_description() VetiverModel.model()\n\n\nMetadata constructors for vetiver model object\nvetiver_meta() vetiver_create_meta()\nvetiver_meta() vetiver_create_meta()\n\n\nCreate a vetiver input data prototype\nvetiver_ptype() vetiver_create_ptype()\nVetiverModel.ptype() _vetiver_create_ptype()\n\n\nConvert new data at prediction time using input data prototype\nvetiver_type_convert()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MLOps with vetiver",
    "section": "",
    "text": "Vetiver, the oil of tranquility, is used as a stabilizing ingredient in perfumery to preserve more volatile fragrances.\n\nThe goal of vetiver is to provide fluent tooling to version, share, deploy, and monitor a trained model. Functions handle both recording and checking the model‚Äôs input data prototype, and predicting from a remote API endpoint.\n\n\n\n\n\n\n\n\n\n\n\nData scientists have effective tools that they ‚ù§Ô∏è to:\n\n\n\n\ncollect data\nprepare, manipulate, refine data\ntrain models\n\n\n\n\n\n\n\n\n\nThere is a lack üò© of effective tools to:\n\n\n\n\nput models into production\nmonitor model performance\ntrigger retraining\n\n\n\nYou can use vetiver for deploying and handling your trained models.\n\nRPython\n\n\n\nlibrary(vetiver)\ncars_lm <- lm(mpg ~ ., data = mtcars)\nvetiver_model(cars_lm, \"cars_linear\")\n\n\n‚îÄ‚îÄ cars_linear ‚îÄ <butchered_lm> model for deployment \nAn OLS linear regression model using 10 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nfrom vetiver.data import mtcars\nfrom sklearn import linear_model\n\nmodel = linear_model.LinearRegression().fit(mtcars, mtcars[\"mpg\"])\nv = VetiverModel(model, model_name = \"cars_linear\", \n                 save_ptype = True, ptype_data = mtcars)\nv.description\n\n\"Scikit-learn <class 'sklearn.linear_model._base.LinearRegression'> model\""
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About vetiver",
    "section": "",
    "text": "Development of vetiver is sponsored by RStudio, PBC."
  },
  {
    "objectID": "about.html#is-vetiver-open-source",
    "href": "about.html#is-vetiver-open-source",
    "title": "About vetiver",
    "section": "Is vetiver open source?",
    "text": "Is vetiver open source?\nThe vetiver Python and R packages are released under the MIT license."
  },
  {
    "objectID": "about.html#what-are-different-ways-you-can-contribute",
    "href": "about.html#what-are-different-ways-you-can-contribute",
    "title": "About vetiver",
    "section": "What are different ways you can contribute?",
    "text": "What are different ways you can contribute?\n\nAnswer questions\nYou can help others use and learn vetiver by answering questions on the RStudio community site, Stack Overflow, and Twitter. Many people asking for help with vetiver don‚Äôt know what a reproducible example or ‚Äúreprex‚Äù is, or how to craft one. Acknowledging an individual‚Äôs problem, showing them how to build a reprex, and pointing them to helpful resources are all enormously beneficial, even if you don‚Äôt immediately solve their problem.\nRemember that while you might have seen a problem a hundred times before, it‚Äôs new to the person asking it. Be patient, polite, and empathetic.\n\n\nFile issues\nIf you‚Äôve found a bug, first create a minimal reproducible example. Spend some time working to make it as minimal as possible; the more time you spend doing this, the easier it is to fix the bug. When your reprex is ready, file it on the GitHub repo of the appropriate package, either Python or R.\nThe vetiver team often focuses on one package at a time to reduce context switching and be more efficient. We may not address each issue right away, but we will use the reproducible example you create to understand your problem when it is time to focus on that package.\n\n\nContribute documentation\nDocumentation is a high priority for vetiver, and pull requests to correct or improve documentation are welcome.\n\n\nContribute code\nIf you are a more experienced R or Python programmer, you may have the inclination, interest, and ability to contribute directly to package development. Before you submit a pull request to vetiver, always file an issue and confirm the vetiver team agrees with your idea and is happy with your basic proposal.\nWe use the tidyverse style guide for R and the PEP 8 style guide for Python. Using a style guide keeps your new code and documentation matching the existing style, and makes the review process much smoother."
  },
  {
    "objectID": "get-started/deploy.html",
    "href": "get-started/deploy.html",
    "title": "Deploy",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(vetiver)\nlibrary(pins)\nhotels <- read_csv('https://tidymodels.org/start/case-study/hotels.csv')\n\nset.seed(123)\nhotel_split <- initial_split(hotels, strata = children)\nhotel_train <- training(hotel_split)\nhotel_test  <- testing(hotel_split)\n\nrf_recipe <- \n  recipe(children ~ ., data = hotel_train) %>% \n  step_date(arrival_date) %>% \n  step_holiday(arrival_date, keep_original_cols = FALSE)\nrf_spec <- rand_forest(mode = \"classification\")\n\nset.seed(234)\nrf_fit <-\n    workflow(rf_recipe, rf_spec) %>%\n    fit(sample_frac(hotel_train, 0.5))\n\nv <- vetiver_model(rf_fit, \"hotel_rf\")\nmodel_board <- board_folder(\".\", versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\n\n\nShow the code from previous steps\nimport pandas as pd\nimport numpy as np\nfrom sklearn import model_selection, preprocessing, pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom vetiver import VetiverModel, vetiver_pin_write\nfrom pins import board_folder\n\nnp.random.seed(500)\n\nraw = pd.read_csv(\"https://tidymodels.org/start/case-study/hotels.csv\")\ndf = pd.DataFrame(raw)\ndf[\"arrival_date\"] = pd.to_datetime(df[\"arrival_date\"])\ndf[\"arrival_month\"] = df[\"arrival_date\"].dt.month\ndf[\"arrival_dow\"] = df[\"arrival_date\"].dt.dayofweek\ndf = df.drop(columns=\"arrival_date\").dropna()\nX, y = df.drop(columns=\"children\"), df[\"children\"]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(\n    X, y, test_size=0.25\n)\n\n## let's only use half of the training data for now\nX_part_1, X_part_2, y_part_1, y_part_2 = model_selection.train_test_split(\n    X_train, y_train, test_size=0.5\n)\n\nle = preprocessing.OrdinalEncoder().fit(X_part_1)\nrf = RandomForestClassifier().fit(le.transform(X_part_1), y_part_1)\nrf = pipeline.Pipeline([(\"label_encoder\", le), (\"random_forest\", rf)])\n\nv = VetiverModel(rf, save_ptype=True, ptype_data=X_part_1, model_name=\"hotel_rf\")\nmodel_board = board_folder(\".\", allow_pickle_read=True)\nvetiver_pin_write(model_board, v)"
  },
  {
    "objectID": "get-started/deploy.html#deploy-your-model",
    "href": "get-started/deploy.html#deploy-your-model",
    "title": "Deploy",
    "section": "Deploy your model",
    "text": "Deploy your model\nYou can deploy your model by creating a special Plumber router in R or a FastAPI router in Python, and adding a POST endpoint for making predictions.\n\nRPython\n\n\n\nlibrary(plumber)\npr() %>%\n  vetiver_api(v)\n\n# Plumber router with 2 endpoints, 4 filters, and 0 sub-routers.\n# Use `pr_run()` on this object to start the API.\n‚îú‚îÄ‚îÄ[queryString]\n‚îú‚îÄ‚îÄ[body]\n‚îú‚îÄ‚îÄ[cookieParser]\n‚îú‚îÄ‚îÄ[sharedSecret]\n‚îú‚îÄ‚îÄ/ping (GET)\n‚îî‚îÄ‚îÄ/predict (POST)\n\n\nTo start a server using this object, pipe (%>%) to pr_run(port = 8080) or your port of choice.\n\n\n\nfrom vetiver import VetiverAPI\napp = VetiverAPI(v, check_ptype = True)\n\nTo start a server using this object, use app.run(port = 8080) or your port of choice.\n\n\n\nYou can interact with your vetiver API locally and debug it. FastAPI and Plumber APIs such as these can be hosted in a variety of ways. You can create a ready-to-go file for deployment that is especially suited for RStudio Connect.\n\nRPython\n\n\n\nvetiver_write_plumber(model_board, \"hotel_rf\")\n\n\n\n# Generated by the vetiver package; edit with care\n\nlibrary(pins)\nlibrary(plumber)\nlibrary(rapidoc)\nlibrary(vetiver)\n\n# Packages needed to generate model predictions\nif (FALSE) {\n    library(dials)\n    library(dplyr)\n    library(parsnip)\n    library(purrr)\n    library(ranger)\n    library(recipes)\n    library(rlang)\n    library(rsample)\n    library(tibble)\n    library(tidyr)\n    library(tune)\n    library(vctrs)\n    library(workflows)\n    library(yardstick)\n}\nb <- board_folder(path = \".\")\nv <- vetiver_pin_read(b, \"hotel_rf\", version = \"20220512T162231Z-404ed\")\n\n#* @plumber\nfunction(pr) {\n    pr %>% vetiver_api(v)\n}\n\n\nFor RStudio Connect, you can streamline this deployment process even more by using vetiver_deploy_rsconnect(model_board, \"hotel_rf\").\n\n\n\napp_file = vetiver_write_app(model_board, \"hotel_rf\")\n\n\n\nimport vetiver\nimport pins\n\n\nb = pins.board_folder('.')\nv = vetiver.vetiver_pin_read(b, 'hotel_rf', version = '20220503T133231Z-c1c86')\n\nvetiver_api = vetiver.VetiverAPI(v)\napi = vetiver_api.app\n\n\n\n\n\nIn a real-world situation, you would see something like board_rsconnect() or board_s3() here instead of our temporary demo board.\n\n\n\n\n\n\nImportant\n\n\n\nNotice that the deployment is strongly linked to a specific version of the pinned model; if you pin another version of the model after you deploy your model, your deployed model will not be affected."
  },
  {
    "objectID": "get-started/deploy.html#generate-a-dockerfile",
    "href": "get-started/deploy.html#generate-a-dockerfile",
    "title": "Deploy",
    "section": "Generate a Dockerfile",
    "text": "Generate a Dockerfile\nFor deploying a vetiver API to infrastructure other than RStudio Connect, such as Google Cloud Run, AWS, or Azure, you likely will want to build a Docker container.\n\n\n\n\n\n\nNote\n\n\n\nYou can use any pins board with Docker, like board_folder() or board_rsconnect(), as long as your Docker container can authenticate to your pins board.\n\n\n\nRPython\n\n\n\nvetiver_write_docker(v)\n\n\n\n# Generated by the vetiver package; edit with care\n\nFROM rocker/r-ver:4.1.2\n\nRUN apt-get update -qq && apt-get install -y --no-install-recommends \\\n  git \\\n  libcurl4-openssl-dev \\\n  libgit2-dev \\\n  libicu-dev \\\n  libsodium-dev \\\n  libssl-dev \\\n  make\n\nCOPY renv.lock /opt/ml/renv.lock\nCOPY plumber.R /opt/ml/plumber.R\n\nRUN Rscript -e \"install.packages(\"renv\")\"\nRUN R -e \"renv::restore()\"\n\nEXPOSE 8000\nENTRYPOINT [\"R\", \"-e\", \"pr <- plumber::plumb(rev(commandArgs())[1]); pr$run(host = '0.0.0.0', port = 8000)\"]\nCMD [\"/opt/ml/plumber.R\"]\n\n\nWhen you run vetiver_write_docker(), you generate two files: the Dockerfile itself and the renv.lock file to capture your model dependencies.\n\n\n\nvetiver_write_docker(app_file)\n\n\n\n# # Generated by the vetiver package; edit with care\n#\nFROM python:3.8\n\n#\nWORKDIR /code\n\n#\nCOPY vetiver_requirements.txt /code/requirements.txt\n\n#\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\n#\nCOPY ./app.py /code/app\n\n#\nCMD [\"uvicorn\", \"app.app:api\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n\n\nTo build the Docker image, you need two files: the Dockerfile itself generated via vetiver_write_docker() and a requirements.txt file to capture your model dependencies. If you don‚Äôt already have a requirements file for your project, vetiver.load_pkgs() will generate one for you, with the name vetiver_requirements.txt.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you build such a Docker container with docker build, all the packages needed to make a prediction with your model are installed into the container.\nWhen you run the Docker container, you can pass in environment variables (for authentication to your pins board, for example) with docker run --env-file .Renviron."
  },
  {
    "objectID": "get-started/deploy.html#predict-from-your-model-endpoint",
    "href": "get-started/deploy.html#predict-from-your-model-endpoint",
    "title": "Deploy",
    "section": "Predict from your model endpoint",
    "text": "Predict from your model endpoint\nA model deployed via vetiver can be treated as a special vetiver_endpoint() object.\n\nRPython\n\n\n\nendpoint <- vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\nendpoint\n\n\n‚îÄ‚îÄ A model API endpoint for prediction: \nhttp://127.0.0.1:8080/predict\n\n\n\n\n\nfrom vetiver.server import predict, vetiver_endpoint\nendpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\nendpoint\n\n'http://127.0.0.1:8080/predict'\n\n\n\n\n\nIf such a deployed model endpoint is running via one process (either remotely on a server or locally, perhaps via a background job in the RStudio IDE), you can make predictions with that deployed model and new data in another, separate process1.\n\nRPython\n\n\n\npredict(endpoint, slice_sample(hotel_test, n = 10))\n\n# A tibble: 10 √ó 1\n   .pred_class\n   <chr>      \n 1 none       \n 2 none       \n 3 children       \n 4 none       \n 5 none       \n 6 none       \n 7 none       \n 8 none       \n 9 children       \n10 none     \n\n\n\npredict(endpoint, hotel_test.df_sample(n = 10))\n\n  prediction\n0       none\n1       none\n2       none\n3       none\n4       none\n5       none\n6       none\n7   children\n8       none\n9       none\n\n\n\nBeing able to predict with a vetiver model endpoint takes advantage of the model‚Äôs input data prototype and other metadata that is stored with the model."
  },
  {
    "objectID": "get-started/index.html",
    "href": "get-started/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "The vetiver framework for MLOps tasks is built for data science teams using R and/or Python, with a native, fluent experience for both. It is built to be extensible, with methods that can support many kinds of models."
  },
  {
    "objectID": "get-started/index.html#installation",
    "href": "get-started/index.html#installation",
    "title": "Getting Started",
    "section": "Installation",
    "text": "Installation\n\nRPython\n\n\nYou can use vetiver with:\n\na tidymodels workflow\ncaret\nmlr3\nXGBoost\nranger\nlm() and glm()\n\nYou can install the released version of vetiver from CRAN:\n\ninstall.packages(\"vetiver\")\n\nAnd the development version from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidymodels/vetiver-r\")\n\n\n\nYou can use vetiver with:\n\nscikit-learn\nPyTorch\n\nYou can install the released version of vetiver from PyPI:\n\npip install vetiver\n\nAnd the development version from GitHub with:\n\npython -m pip install git+https://github.com/tidymodels/vetiver-python"
  },
  {
    "objectID": "get-started/index.html#create-a-vetiver-model",
    "href": "get-started/index.html#create-a-vetiver-model",
    "title": "Getting Started",
    "section": "Create a vetiver model",
    "text": "Create a vetiver model\nFor this example, let‚Äôs work with data on hotel bookings to predict which hotel stays included children and which did not.\n\nRPython\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a tidymodels workflow that encompasses both feature engineering and model estimation.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nhotels <- read_csv('https://tidymodels.org/start/case-study/hotels.csv')\n\nset.seed(123)\nhotel_split <- initial_split(hotels, strata = children)\nhotel_train <- training(hotel_split)\nhotel_test  <- testing(hotel_split)\n\nrf_recipe <- \n  recipe(children ~ ., data = hotel_train) %>% \n  step_date(arrival_date) %>% \n  step_holiday(arrival_date, keep_original_cols = FALSE)\nrf_spec <- rand_forest(mode = \"classification\")\n\nset.seed(234)\n## let's only use half of the training data for now\nrf <-\n    workflow(rf_recipe, rf_spec) %>%\n    fit(sample_frac(hotel_train, 0.5))\n\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a scikit-learn pipeline that encompasses both feature engineering and model estimation.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import model_selection, preprocessing, pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(500)\n\nraw = pd.read_csv(\"https://tidymodels.org/start/case-study/hotels.csv\")\ndf = pd.DataFrame(raw)\ndf[\"arrival_date\"] = pd.to_datetime(df[\"arrival_date\"])\ndf[\"arrival_month\"] = df[\"arrival_date\"].dt.month\ndf[\"arrival_dow\"] = df[\"arrival_date\"].dt.dayofweek\ndf = df.drop(columns=\"arrival_date\").dropna()\nX, y = df.drop(columns=\"children\"), df[\"children\"]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(\n    X, y, test_size=0.25\n)\n\n## let's only use half of the training data for now\nX_part_1, X_part_2, y_part_1, y_part_2 = model_selection.train_test_split(\n    X_train, y_train, test_size=0.5\n)\n\nle = preprocessing.OrdinalEncoder().fit(X_part_1)\nrf = RandomForestClassifier().fit(le.transform(X_part_1), y_part_1)\nrf = pipeline.Pipeline([(\"label_encoder\", le), (\"random_forest\", rf)])\n\n\n\n\nThis rf object is a fitted model, with both feature engineering and model parameters estimated using some of the training data hotel_train. We can create a vetiver_model() in R or VetiverModel() in Python from the trained model; a vetiver model object collects the information needed to store, version, and deploy a trained model.\n\nRPython\n\n\n\nlibrary(vetiver)\nv <- vetiver_model(rf, \"hotel_rf\")\nv\n\n\n‚îÄ‚îÄ hotel_rf ‚îÄ <butchered_workflow> model for deployment \nA ranger classification modeling workflow using 22 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nv = VetiverModel(\n    rf,  model_name = \"hotel_rf\", \n    save_ptype = True, ptype_data = X_part_1\n)\nv.description\n\n\"Scikit-learn <class 'sklearn.pipeline.Pipeline'> model\"\n\n\n\n\n\nThink of this vetiver model as a deployable model object."
  },
  {
    "objectID": "get-started/version.html",
    "href": "get-started/version.html",
    "title": "Version",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(vetiver)\nhotels <- read_csv('https://tidymodels.org/start/case-study/hotels.csv')\n\nset.seed(123)\nhotel_split <- initial_split(hotels, strata = children)\nhotel_train <- training(hotel_split)\nhotel_test  <- testing(hotel_split)\n\nrf_recipe <- \n  recipe(children ~ ., data = hotel_train) %>% \n  step_date(arrival_date) %>% \n  step_holiday(arrival_date, keep_original_cols = FALSE)\nrf_spec <- rand_forest(mode = \"classification\")\n\nset.seed(234)\nrf_fit <-\n    workflow(rf_recipe, rf_spec) %>%\n    fit(sample_frac(hotel_train, 0.5))\n\nv <- vetiver_model(rf_fit, \"hotel_rf\")\n\n\n\n\n\n\nShow the code from previous steps\nimport pandas as pd\nimport numpy as np\nfrom sklearn import model_selection, preprocessing, pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom vetiver import VetiverModel\n\nnp.random.seed(500)\n\nraw = pd.read_csv(\"https://tidymodels.org/start/case-study/hotels.csv\")\ndf = pd.DataFrame(raw)\ndf[\"arrival_date\"] = pd.to_datetime(df[\"arrival_date\"])\ndf[\"arrival_month\"] = df[\"arrival_date\"].dt.month\ndf[\"arrival_dow\"] = df[\"arrival_date\"].dt.dayofweek\ndf = df.drop(columns=\"arrival_date\").dropna()\nX, y = df.drop(columns=\"children\"), df[\"children\"]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(\n    X, y, test_size=0.25\n)\n\n## let's only use half of the training data for now\nX_part_1, X_part_2, y_part_1, y_part_2 = model_selection.train_test_split(\n    X_train, y_train, test_size=0.5\n)\n\nle = preprocessing.OrdinalEncoder().fit(X_part_1)\nrf = RandomForestClassifier().fit(le.transform(X_part_1), y_part_1)\nrf = pipeline.Pipeline([(\"label_encoder\", le), (\"random_forest\", rf)])\n\nv = VetiverModel(rf, save_ptype=True, ptype_data=X_part_1, model_name=\"hotel_rf\")"
  },
  {
    "objectID": "get-started/version.html#store-and-version-your-model",
    "href": "get-started/version.html#store-and-version-your-model",
    "title": "Version",
    "section": "Store and version your model",
    "text": "Store and version your model\nYou can store and version your model by choosing a pins ‚Äúboard‚Äù for it, including a local folder, RStudio Connect, Amazon S3, and more. When we write the vetiver model to our board, the binary model object is stored on our board together with necessary metadata, like the packages needed to make a prediction and the model‚Äôs input data prototype for checking new data at prediction time.\n\n\n\n\n\n\nNote\n\n\n\nWe‚Äôll use a temporary board that will be automatically deleted for this demo, but for your real work, you will want to choose the best board for your particular infrastructure.\n\n\n\nRPython\n\n\nMost pins boards have versioning turned on by default, but we can turn it on explicitly for our temporary demo board.\n\nlibrary(pins)\nmodel_board <- board_temp(versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\nfrom pins import board_temp\nfrom vetiver import vetiver_pin_write\nmodel_board = board_temp(versioned = True, allow_pickle_read = True)\nvetiver_pin_write(model_board, v)\n\n\n\n\nLet‚Äôs train our model again with a new version of the dataset and write it once more to our board.\n\nRPython\n\n\n\n## use a different random subset of the training data\nrf <-\n    workflow(rf_recipe, rf_spec) %>%\n    fit(sample_frac(hotel_train, 0.5))\n\nv <- vetiver_model(rf, \"hotel_rf\")\n\nmodel_board %>% vetiver_pin_write(v)\n\nCreating new version '20220512T162301Z-8f681'\n\n\nWriting to pin 'hotel_rf'\n\n\n\n\n\n## use a different random subset of the training data\nX_part_1, X_part_2, y_part_1, y_part_2 = model_selection.train_test_split(\n    X_train, y_train, test_size = 0.5\n)\n\nle = preprocessing.OrdinalEncoder().fit(X_part_1)\nrf = RandomForestClassifier().fit(le.transform(X_part_1), y_part_1)\nrf = pipeline.Pipeline([(\"label_encoder\", le), (\"random_forest\", rf)])\n\nv = VetiverModel(rf, model_name = \"hotel_rf\", \n                 save_ptype = True, ptype_data = X_part_1)\nvetiver_pin_write(model_board, v)\n\n\n\n\nBoth versions are stored, and we have access to both.\n\nRPython\n\n\n\nmodel_board %>% pin_versions(\"hotel_rf\")\n\n# A tibble: 2 √ó 3\n  version                created             hash \n  <chr>                  <dttm>              <chr>\n1 20220512T162256Z-2d161 2022-05-12 12:22:00 2d161\n2 20220512T162301Z-8f681 2022-05-12 12:23:00 8f681\n\n\n\n\n\nmodel_board.pin_versions(\"hotel_rf\")\n\n              created   hash                 version\n0 2022-05-12 12:22:56  a4758  20220512T122256Z-a4758\n1 2022-05-12 12:23:03  6cd19  20220512T122303Z-6cd19\n\n\n\n\n\nThe primary purpose of pins is to make it easy to share data artifacts, so depending on the board you choose, your pinned vetiver model can be shareable with your collaborators."
  },
  {
    "objectID": "get-started/monitor.html",
    "href": "get-started/monitor.html",
    "title": "Monitor",
    "section": "",
    "text": "üöß COMING SOON üöß"
  }
]